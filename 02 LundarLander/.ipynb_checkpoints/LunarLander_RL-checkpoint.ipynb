{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adapted-terminal",
   "metadata": {},
   "source": [
    "# Project 02  - LunarLander in OpenAI\n",
    "## [Tutorial]\n",
    "https://www.youtube.com/watch?v=nRHjymV2PX8&t=1230s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-bankruptcy",
   "metadata": {},
   "source": [
    "# 0. Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-labor",
   "metadata": {},
   "source": [
    "## [Remark]\n",
    "#using stable baselines have to use tensorflow version before tensorflow 2.0 <br>\n",
    "#install tensorflow & tensorflow-gpu to work for non-GPU and GPU machine\n",
    "\n",
    "#stable_baselines library <br>\n",
    "#gym library  <br>\n",
    "#box2d for lunarLander <br>\n",
    "#--user to install dependencises in local account to avoid adminstration issue  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ranging-clerk",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15.0 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (1.15.0)\n",
      "Requirement already satisfied: tensorflow-gpu==1.15.0 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==1.15.0) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==1.15.0) (3.15.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==1.15.0) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==1.15.0) (0.12.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.0) (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.0) (0.8.1)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.0) (1.15.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.0) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==1.15.0) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==1.15.0) (0.36.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.0) (1.15.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.0) (1.18.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow==1.15.0) (1.32.0)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.0) (0.2.2)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15.0 tensorflow-gpu==1.15.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thorough-speed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable_baselines in c:\\programdata\\anaconda3\\lib\\site-packages (2.10.2)\n",
      "Requirement already satisfied: gym in c:\\programdata\\anaconda3\\lib\\site-packages (0.18.3)\n",
      "Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym) (1.5.15)\n",
      "Requirement already satisfied: scipy in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from gym) (1.18.5)\n",
      "Requirement already satisfied: Pillow<=8.2.0 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from gym) (8.1.2)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from stable_baselines) (1.0.1)\n",
      "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\lib\\site-packages (from stable_baselines) (4.5.3.56)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from stable_baselines) (1.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from stable_baselines) (3.4.0)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym) (0.2.9)\n",
      "Requirement already satisfied: six in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from atari-py~=0.2.0->gym) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->stable_baselines) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->stable_baselines) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->stable_baselines) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->stable_baselines) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->stable_baselines) (2021.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable_baselines gym --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-heath",
   "metadata": {},
   "source": [
    "## [Remark]\n",
    "#in case of error in installing box2d-py ---> run \"conda install swig\" in Anaconda <br>\n",
    "#Ancaonda shall run as adminsistrator if user do not have write permission to the target en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "martial-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fail\n",
    "#!pip install box2D-py --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "musical-senate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Box2D in c:\\users\\hilbert ng\\appdata\\roaming\\python\\python37\\site-packages (2.3.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install Box2D --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-oxford",
   "metadata": {},
   "source": [
    "# 1. Test Random Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from stable_baselines import ACER\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "packed-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'LunarLander-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stopped-charity",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-14801f321451>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "states = env.observation_space\n",
    "actions = env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "invisible-footage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ranking-farmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "intermediate-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-276.4368283485017\n",
      "Episode:2 Score:-91.97602656978708\n",
      "Episode:3 Score:-576.207238109173\n",
      "Episode:4 Score:-466.92295910106776\n",
      "Episode:5 Score:-147.9196804286011\n",
      "Episode:6 Score:-243.38964230023117\n",
      "Episode:7 Score:-108.59226876672267\n",
      "Episode:8 Score:-145.74838655706844\n",
      "Episode:9 Score:-226.51622902903955\n",
      "Episode:10 Score:-79.91908646715402\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range (1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-worker",
   "metadata": {},
   "source": [
    "# 2. Build and Traing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-bahrain",
   "metadata": {},
   "source": [
    "## [Remark]\n",
    "#MlpPolicy = multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tough-shepherd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Hilbert Ng\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Hilbert Ng\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\training\\moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\acer\\acer_simple.py:421: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\acer\\acer_simple.py:453: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Hilbert Ng\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\acer\\acer_simple.py:479: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Hilbert Ng\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\acer\\acer_simple.py:504: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\acer\\acer_simple.py:506: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = ACER('MlpPolicy', env, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-technical",
   "metadata": {},
   "source": [
    "## [Remark]\n",
    "#train for high \"explained_variance\" (close to one) & \"mean_episode_reward\" (as high as possible) <br>\n",
    "#stop when the result is high enough to avoid overfitting or getting poor result (can use \"callback\" for automatic pause training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "educated-label",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 0.726    |\n",
      "| avg_norm_g          | 5.07     |\n",
      "| avg_norm_grads_f    | 4.64     |\n",
      "| avg_norm_k          | 2        |\n",
      "| avg_norm_k_dot_g    | 5.07     |\n",
      "| entropy             | 29.1     |\n",
      "| explained_variance  | 0.00165  |\n",
      "| fps                 | 0        |\n",
      "| loss                | -0.0525  |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.547   |\n",
      "| loss_policy         | -0.547   |\n",
      "| loss_q              | 1.57     |\n",
      "| mean_episode_length | 0        |\n",
      "| mean_episode_reward | 0        |\n",
      "| norm_grads          | 2.12     |\n",
      "| norm_grads_policy   | 1.87     |\n",
      "| norm_grads_q        | 1        |\n",
      "| total_timesteps     | 20       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 15.5     |\n",
      "| avg_norm_g          | 63.2     |\n",
      "| avg_norm_grads_f    | 54.7     |\n",
      "| avg_norm_k          | 2        |\n",
      "| avg_norm_k_dot_g    | 63.4     |\n",
      "| entropy             | 29       |\n",
      "| explained_variance  | -0.00961 |\n",
      "| fps                 | 553      |\n",
      "| loss                | 60.4     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -21.9    |\n",
      "| loss_policy         | -21.9    |\n",
      "| loss_q              | 165      |\n",
      "| mean_episode_length | 90.6     |\n",
      "| mean_episode_reward | -151     |\n",
      "| norm_grads          | 19.6     |\n",
      "| norm_grads_policy   | 8.04     |\n",
      "| norm_grads_q        | 17.9     |\n",
      "| total_timesteps     | 2020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 6.1      |\n",
      "| avg_norm_g          | 26.7     |\n",
      "| avg_norm_grads_f    | 23.2     |\n",
      "| avg_norm_k          | 2.1      |\n",
      "| avg_norm_k_dot_g    | 27.9     |\n",
      "| entropy             | 27       |\n",
      "| explained_variance  | -0.142   |\n",
      "| fps                 | 538      |\n",
      "| loss                | 4.65     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -8.63    |\n",
      "| loss_policy         | -8.63    |\n",
      "| loss_q              | 27.1     |\n",
      "| mean_episode_length | 93.8     |\n",
      "| mean_episode_reward | -152     |\n",
      "| norm_grads          | 16       |\n",
      "| norm_grads_policy   | 1.89     |\n",
      "| norm_grads_q        | 15.9     |\n",
      "| total_timesteps     | 4020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 6.73     |\n",
      "| avg_norm_g          | 55.5     |\n",
      "| avg_norm_grads_f    | 52       |\n",
      "| avg_norm_k          | 2.79     |\n",
      "| avg_norm_k_dot_g    | 53.3     |\n",
      "| entropy             | 12.8     |\n",
      "| explained_variance  | 0.0304   |\n",
      "| fps                 | 515      |\n",
      "| loss                | 138      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -16.5    |\n",
      "| loss_policy         | -16.5    |\n",
      "| loss_q              | 309      |\n",
      "| mean_episode_length | 117      |\n",
      "| mean_episode_reward | -131     |\n",
      "| norm_grads          | 75.7     |\n",
      "| norm_grads_policy   | 36.7     |\n",
      "| norm_grads_q        | 66.2     |\n",
      "| total_timesteps     | 6020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 96.5     |\n",
      "| avg_norm_grads_f    | 96.5     |\n",
      "| avg_norm_k          | 2.12     |\n",
      "| avg_norm_k_dot_g    | 103      |\n",
      "| entropy             | 16.7     |\n",
      "| explained_variance  | -0.0145  |\n",
      "| fps                 | 475      |\n",
      "| loss                | 59.1     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 13.6     |\n",
      "| loss_policy         | 13.6     |\n",
      "| loss_q              | 91.4     |\n",
      "| mean_episode_length | 163      |\n",
      "| mean_episode_reward | -159     |\n",
      "| norm_grads          | 32.9     |\n",
      "| norm_grads_policy   | 18.4     |\n",
      "| norm_grads_q        | 27.3     |\n",
      "| total_timesteps     | 8020     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| avg_norm_adj        | 0         |\n",
      "| avg_norm_g          | 36.5      |\n",
      "| avg_norm_grads_f    | 36.5      |\n",
      "| avg_norm_k          | 2.06      |\n",
      "| avg_norm_k_dot_g    | 36.2      |\n",
      "| entropy             | 17.5      |\n",
      "| explained_variance  | -0.000835 |\n",
      "| fps                 | 424       |\n",
      "| loss                | 105       |\n",
      "| loss_bc             | -0        |\n",
      "| loss_f              | 11.5      |\n",
      "| loss_policy         | 11.5      |\n",
      "| loss_q              | 187       |\n",
      "| mean_episode_length | 208       |\n",
      "| mean_episode_reward | -151      |\n",
      "| norm_grads          | 52.5      |\n",
      "| norm_grads_policy   | 7.31      |\n",
      "| norm_grads_q        | 52        |\n",
      "| total_timesteps     | 10020     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 1.56     |\n",
      "| avg_norm_grads_f    | 1.56     |\n",
      "| avg_norm_k          | 2.25     |\n",
      "| avg_norm_k_dot_g    | 1.61     |\n",
      "| entropy             | 21.1     |\n",
      "| explained_variance  | 0.0653   |\n",
      "| fps                 | 425      |\n",
      "| loss                | 0.43     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.532    |\n",
      "| loss_policy         | 0.532    |\n",
      "| loss_q              | 0.219    |\n",
      "| mean_episode_length | 233      |\n",
      "| mean_episode_reward | -145     |\n",
      "| norm_grads          | 2.81     |\n",
      "| norm_grads_policy   | 0.374    |\n",
      "| norm_grads_q        | 2.78     |\n",
      "| total_timesteps     | 12020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 39.6     |\n",
      "| avg_norm_grads_f    | 39.6     |\n",
      "| avg_norm_k          | 2.03     |\n",
      "| avg_norm_k_dot_g    | 39.4     |\n",
      "| entropy             | 13.2     |\n",
      "| explained_variance  | -0.0521  |\n",
      "| fps                 | 434      |\n",
      "| loss                | 131      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 11.9     |\n",
      "| loss_policy         | 11.9     |\n",
      "| loss_q              | 238      |\n",
      "| mean_episode_length | 283      |\n",
      "| mean_episode_reward | -116     |\n",
      "| norm_grads          | 77.8     |\n",
      "| norm_grads_policy   | 10.2     |\n",
      "| norm_grads_q        | 77.1     |\n",
      "| total_timesteps     | 14020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 11.7     |\n",
      "| avg_norm_g          | 46.1     |\n",
      "| avg_norm_grads_f    | 39.5     |\n",
      "| avg_norm_k          | 2.06     |\n",
      "| avg_norm_k_dot_g    | 46.8     |\n",
      "| entropy             | 21.8     |\n",
      "| explained_variance  | -0.00904 |\n",
      "| fps                 | 447      |\n",
      "| loss                | 34.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -12.6    |\n",
      "| loss_policy         | -12.6    |\n",
      "| loss_q              | 95       |\n",
      "| mean_episode_length | 317      |\n",
      "| mean_episode_reward | -112     |\n",
      "| norm_grads          | 67.5     |\n",
      "| norm_grads_policy   | 41.9     |\n",
      "| norm_grads_q        | 52.9     |\n",
      "| total_timesteps     | 16020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 13.6     |\n",
      "| avg_norm_g          | 50.9     |\n",
      "| avg_norm_grads_f    | 43.8     |\n",
      "| avg_norm_k          | 1.94     |\n",
      "| avg_norm_k_dot_g    | 48.8     |\n",
      "| entropy             | 15.3     |\n",
      "| explained_variance  | -0.306   |\n",
      "| fps                 | 457      |\n",
      "| loss                | 40.2     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -12.2    |\n",
      "| loss_policy         | -12.2    |\n",
      "| loss_q              | 105      |\n",
      "| mean_episode_length | 343      |\n",
      "| mean_episode_reward | -103     |\n",
      "| norm_grads          | 65.1     |\n",
      "| norm_grads_policy   | 29.5     |\n",
      "| norm_grads_q        | 58       |\n",
      "| total_timesteps     | 18020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 5.81     |\n",
      "| avg_norm_g          | 30.1     |\n",
      "| avg_norm_grads_f    | 27       |\n",
      "| avg_norm_k          | 2.1      |\n",
      "| avg_norm_k_dot_g    | 30       |\n",
      "| entropy             | 8.91     |\n",
      "| explained_variance  | -0.335   |\n",
      "| fps                 | 458      |\n",
      "| loss                | 608      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -2.49    |\n",
      "| loss_policy         | -2.49    |\n",
      "| loss_q              | 1.22e+03 |\n",
      "| mean_episode_length | 377      |\n",
      "| mean_episode_reward | -96.9    |\n",
      "| norm_grads          | 139      |\n",
      "| norm_grads_policy   | 24.4     |\n",
      "| norm_grads_q        | 137      |\n",
      "| total_timesteps     | 20020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 3.01     |\n",
      "| avg_norm_g          | 23.8     |\n",
      "| avg_norm_grads_f    | 21.4     |\n",
      "| avg_norm_k          | 1.51     |\n",
      "| avg_norm_k_dot_g    | 22.1     |\n",
      "| entropy             | 10.1     |\n",
      "| explained_variance  | 0.271    |\n",
      "| fps                 | 466      |\n",
      "| loss                | 81.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 4.84     |\n",
      "| loss_policy         | 4.84     |\n",
      "| loss_q              | 154      |\n",
      "| mean_episode_length | 367      |\n",
      "| mean_episode_reward | -80.3    |\n",
      "| norm_grads          | 29.1     |\n",
      "| norm_grads_policy   | 7.76     |\n",
      "| norm_grads_q        | 28       |\n",
      "| total_timesteps     | 22020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 0.237    |\n",
      "| avg_norm_g          | 25.3     |\n",
      "| avg_norm_grads_f    | 25.1     |\n",
      "| avg_norm_k          | 1.81     |\n",
      "| avg_norm_k_dot_g    | 23.2     |\n",
      "| entropy             | 8.85     |\n",
      "| explained_variance  | -0.252   |\n",
      "| fps                 | 473      |\n",
      "| loss                | 84.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 7.67     |\n",
      "| loss_policy         | 7.67     |\n",
      "| loss_q              | 154      |\n",
      "| mean_episode_length | 291      |\n",
      "| mean_episode_reward | -95.8    |\n",
      "| norm_grads          | 74.7     |\n",
      "| norm_grads_policy   | 3.89     |\n",
      "| norm_grads_q        | 74.6     |\n",
      "| total_timesteps     | 24020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 33.9     |\n",
      "| avg_norm_grads_f    | 33.9     |\n",
      "| avg_norm_k          | 2.32     |\n",
      "| avg_norm_k_dot_g    | 39.4     |\n",
      "| entropy             | 11.2     |\n",
      "| explained_variance  | -0.477   |\n",
      "| fps                 | 479      |\n",
      "| loss                | 105      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 9.31     |\n",
      "| loss_policy         | 9.31     |\n",
      "| loss_q              | 193      |\n",
      "| mean_episode_length | 271      |\n",
      "| mean_episode_reward | -102     |\n",
      "| norm_grads          | 261      |\n",
      "| norm_grads_policy   | 1.62     |\n",
      "| norm_grads_q        | 261      |\n",
      "| total_timesteps     | 26020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 37.6     |\n",
      "| avg_norm_grads_f    | 37.6     |\n",
      "| avg_norm_k          | 2.38     |\n",
      "| avg_norm_k_dot_g    | 44.7     |\n",
      "| entropy             | 8.75     |\n",
      "| explained_variance  | 0.105    |\n",
      "| fps                 | 486      |\n",
      "| loss                | 64.5     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 8.72     |\n",
      "| loss_policy         | 8.72     |\n",
      "| loss_q              | 112      |\n",
      "| mean_episode_length | 252      |\n",
      "| mean_episode_reward | -102     |\n",
      "| norm_grads          | 159      |\n",
      "| norm_grads_policy   | 22.5     |\n",
      "| norm_grads_q        | 158      |\n",
      "| total_timesteps     | 28020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 585      |\n",
      "| avg_norm_grads_f    | 585      |\n",
      "| avg_norm_k          | 1.89     |\n",
      "| avg_norm_k_dot_g    | 495      |\n",
      "| entropy             | 12.9     |\n",
      "| explained_variance  | -1.18    |\n",
      "| fps                 | 490      |\n",
      "| loss                | 147      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 19.8     |\n",
      "| loss_policy         | 19.8     |\n",
      "| loss_q              | 254      |\n",
      "| mean_episode_length | 221      |\n",
      "| mean_episode_reward | -81.4    |\n",
      "| norm_grads          | 229      |\n",
      "| norm_grads_policy   | 14.4     |\n",
      "| norm_grads_q        | 229      |\n",
      "| total_timesteps     | 30020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0738   |\n",
      "| avg_norm_g          | 12.4     |\n",
      "| avg_norm_grads_f    | 12.4     |\n",
      "| avg_norm_k          | 1.97     |\n",
      "| avg_norm_k_dot_g    | 13.1     |\n",
      "| entropy             | 8.08     |\n",
      "| explained_variance  | -0.0526  |\n",
      "| fps                 | 490      |\n",
      "| loss                | 32.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 3.68     |\n",
      "| loss_policy         | 3.68     |\n",
      "| loss_q              | 58.2     |\n",
      "| mean_episode_length | 241      |\n",
      "| mean_episode_reward | -60.8    |\n",
      "| norm_grads          | 76.4     |\n",
      "| norm_grads_policy   | 26       |\n",
      "| norm_grads_q        | 71.9     |\n",
      "| total_timesteps     | 32020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 13       |\n",
      "| avg_norm_grads_f    | 13       |\n",
      "| avg_norm_k          | 1.96     |\n",
      "| avg_norm_k_dot_g    | 13.4     |\n",
      "| entropy             | 13.1     |\n",
      "| explained_variance  | 0.469    |\n",
      "| fps                 | 487      |\n",
      "| loss                | 18.9     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 3.84     |\n",
      "| loss_policy         | 3.84     |\n",
      "| loss_q              | 30.5     |\n",
      "| mean_episode_length | 244      |\n",
      "| mean_episode_reward | -31.6    |\n",
      "| norm_grads          | 72.1     |\n",
      "| norm_grads_policy   | 5.26     |\n",
      "| norm_grads_q        | 71.9     |\n",
      "| total_timesteps     | 34020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.591    |\n",
      "| avg_norm_g          | 5.17     |\n",
      "| avg_norm_grads_f    | 4.8      |\n",
      "| avg_norm_k          | 2.05     |\n",
      "| avg_norm_k_dot_g    | 5.12     |\n",
      "| entropy             | 21.1     |\n",
      "| explained_variance  | -0.166   |\n",
      "| fps                 | 484      |\n",
      "| loss                | 1.07     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.227   |\n",
      "| loss_policy         | -0.227   |\n",
      "| loss_q              | 3.01     |\n",
      "| mean_episode_length | 260      |\n",
      "| mean_episode_reward | -5.06    |\n",
      "| norm_grads          | 10.8     |\n",
      "| norm_grads_policy   | 5.88     |\n",
      "| norm_grads_q        | 9.02     |\n",
      "| total_timesteps     | 36020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 31.6     |\n",
      "| avg_norm_grads_f    | 31.6     |\n",
      "| avg_norm_k          | 2.1      |\n",
      "| avg_norm_k_dot_g    | 31.9     |\n",
      "| entropy             | 14.3     |\n",
      "| explained_variance  | -0.832   |\n",
      "| fps                 | 478      |\n",
      "| loss                | 105      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 9.55     |\n",
      "| loss_policy         | 9.55     |\n",
      "| loss_q              | 191      |\n",
      "| mean_episode_length | 280      |\n",
      "| mean_episode_reward | 12.6     |\n",
      "| norm_grads          | 235      |\n",
      "| norm_grads_policy   | 8.85     |\n",
      "| norm_grads_q        | 235      |\n",
      "| total_timesteps     | 38020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 11       |\n",
      "| avg_norm_grads_f    | 11       |\n",
      "| avg_norm_k          | 1.85     |\n",
      "| avg_norm_k_dot_g    | 8.97     |\n",
      "| entropy             | 12.9     |\n",
      "| explained_variance  | 0.883    |\n",
      "| fps                 | 472      |\n",
      "| loss                | 12.4     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 3.26     |\n",
      "| loss_policy         | 3.26     |\n",
      "| loss_q              | 18.5     |\n",
      "| mean_episode_length | 302      |\n",
      "| mean_episode_reward | 25.1     |\n",
      "| norm_grads          | 117      |\n",
      "| norm_grads_policy   | 16.1     |\n",
      "| norm_grads_q        | 116      |\n",
      "| total_timesteps     | 40020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 1.52     |\n",
      "| avg_norm_grads_f    | 1.52     |\n",
      "| avg_norm_k          | 1.66     |\n",
      "| avg_norm_k_dot_g    | 1.52     |\n",
      "| entropy             | 0.306    |\n",
      "| explained_variance  | 0.013    |\n",
      "| fps                 | 469      |\n",
      "| loss                | 0.775    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.00279  |\n",
      "| loss_policy         | 0.00279  |\n",
      "| loss_q              | 1.55     |\n",
      "| mean_episode_length | 322      |\n",
      "| mean_episode_reward | 34.3     |\n",
      "| norm_grads          | 6.25     |\n",
      "| norm_grads_policy   | 0.0237   |\n",
      "| norm_grads_q        | 6.25     |\n",
      "| total_timesteps     | 42020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 2.97     |\n",
      "| avg_norm_g          | 11.9     |\n",
      "| avg_norm_grads_f    | 10.2     |\n",
      "| avg_norm_k          | 2.01     |\n",
      "| avg_norm_k_dot_g    | 11.6     |\n",
      "| entropy             | 18.3     |\n",
      "| explained_variance  | 0.94     |\n",
      "| fps                 | 468      |\n",
      "| loss                | 5.37     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -3.43    |\n",
      "| loss_policy         | -3.43    |\n",
      "| loss_q              | 18       |\n",
      "| mean_episode_length | 297      |\n",
      "| mean_episode_reward | 32.7     |\n",
      "| norm_grads          | 134      |\n",
      "| norm_grads_policy   | 17.2     |\n",
      "| norm_grads_q        | 133      |\n",
      "| total_timesteps     | 44020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 18.6     |\n",
      "| avg_norm_grads_f    | 18.6     |\n",
      "| avg_norm_k          | 2.01     |\n",
      "| avg_norm_k_dot_g    | 17.9     |\n",
      "| entropy             | 13.5     |\n",
      "| explained_variance  | -0.0633  |\n",
      "| fps                 | 465      |\n",
      "| loss                | 40.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 5.63     |\n",
      "| loss_policy         | 5.63     |\n",
      "| loss_q              | 70.4     |\n",
      "| mean_episode_length | 302      |\n",
      "| mean_episode_reward | 50.3     |\n",
      "| norm_grads          | 37.7     |\n",
      "| norm_grads_policy   | 9.25     |\n",
      "| norm_grads_q        | 36.6     |\n",
      "| total_timesteps     | 46020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 1.81     |\n",
      "| avg_norm_g          | 8.31     |\n",
      "| avg_norm_grads_f    | 7.26     |\n",
      "| avg_norm_k          | 1.99     |\n",
      "| avg_norm_k_dot_g    | 8.4      |\n",
      "| entropy             | 10.5     |\n",
      "| explained_variance  | 0.473    |\n",
      "| fps                 | 466      |\n",
      "| loss                | -0.188   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.5     |\n",
      "| loss_policy         | -1.5     |\n",
      "| loss_q              | 2.84     |\n",
      "| mean_episode_length | 269      |\n",
      "| mean_episode_reward | 30.8     |\n",
      "| norm_grads          | 16.8     |\n",
      "| norm_grads_policy   | 4.69     |\n",
      "| norm_grads_q        | 16.1     |\n",
      "| total_timesteps     | 48020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 3.4      |\n",
      "| avg_norm_g          | 14.7     |\n",
      "| avg_norm_grads_f    | 12.8     |\n",
      "| avg_norm_k          | 2.04     |\n",
      "| avg_norm_k_dot_g    | 15.1     |\n",
      "| entropy             | 18.7     |\n",
      "| explained_variance  | 0.831    |\n",
      "| fps                 | 464      |\n",
      "| loss                | 7.86     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -4.44    |\n",
      "| loss_policy         | -4.44    |\n",
      "| loss_q              | 25       |\n",
      "| mean_episode_length | 254      |\n",
      "| mean_episode_reward | 32.5     |\n",
      "| norm_grads          | 123      |\n",
      "| norm_grads_policy   | 4.9      |\n",
      "| norm_grads_q        | 123      |\n",
      "| total_timesteps     | 50020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.268    |\n",
      "| avg_norm_g          | 1.7      |\n",
      "| avg_norm_grads_f    | 1.5      |\n",
      "| avg_norm_k          | 1.73     |\n",
      "| avg_norm_k_dot_g    | 1.7      |\n",
      "| entropy             | 0.573    |\n",
      "| explained_variance  | -0.0594  |\n",
      "| fps                 | 460      |\n",
      "| loss                | 0.859    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.00673 |\n",
      "| loss_policy         | -0.00673 |\n",
      "| loss_q              | 1.74     |\n",
      "| mean_episode_length | 260      |\n",
      "| mean_episode_reward | 37.3     |\n",
      "| norm_grads          | 9.64     |\n",
      "| norm_grads_policy   | 0.0687   |\n",
      "| norm_grads_q        | 9.64     |\n",
      "| total_timesteps     | 52020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0359   |\n",
      "| avg_norm_g          | 28.7     |\n",
      "| avg_norm_grads_f    | 28.7     |\n",
      "| avg_norm_k          | 1.8      |\n",
      "| avg_norm_k_dot_g    | 23.3     |\n",
      "| entropy             | 10       |\n",
      "| explained_variance  | -0.668   |\n",
      "| fps                 | 459      |\n",
      "| loss                | 20.3     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 3.61     |\n",
      "| loss_policy         | 3.61     |\n",
      "| loss_q              | 33.5     |\n",
      "| mean_episode_length | 275      |\n",
      "| mean_episode_reward | 52.3     |\n",
      "| norm_grads          | 184      |\n",
      "| norm_grads_policy   | 9.38     |\n",
      "| norm_grads_q        | 183      |\n",
      "| total_timesteps     | 54020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 12.4     |\n",
      "| avg_norm_grads_f    | 12.4     |\n",
      "| avg_norm_k          | 2.1      |\n",
      "| avg_norm_k_dot_g    | 14.4     |\n",
      "| entropy             | 12.1     |\n",
      "| explained_variance  | -0.37    |\n",
      "| fps                 | 456      |\n",
      "| loss                | 13.9     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 3.67     |\n",
      "| loss_policy         | 3.67     |\n",
      "| loss_q              | 20.7     |\n",
      "| mean_episode_length | 292      |\n",
      "| mean_episode_reward | 67.9     |\n",
      "| norm_grads          | 24       |\n",
      "| norm_grads_policy   | 11.4     |\n",
      "| norm_grads_q        | 21.1     |\n",
      "| total_timesteps     | 56020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 6.73     |\n",
      "| avg_norm_grads_f    | 6.73     |\n",
      "| avg_norm_k          | 1.7      |\n",
      "| avg_norm_k_dot_g    | 6.74     |\n",
      "| entropy             | 0.367    |\n",
      "| explained_variance  | -2.53    |\n",
      "| fps                 | 453      |\n",
      "| loss                | 25.6     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.0909   |\n",
      "| loss_policy         | 0.0909   |\n",
      "| loss_q              | 51.1     |\n",
      "| mean_episode_length | 292      |\n",
      "| mean_episode_reward | 65       |\n",
      "| norm_grads          | 59.6     |\n",
      "| norm_grads_policy   | 1.44     |\n",
      "| norm_grads_q        | 59.6     |\n",
      "| total_timesteps     | 58020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 3.17     |\n",
      "| avg_norm_g          | 15.5     |\n",
      "| avg_norm_grads_f    | 13.9     |\n",
      "| avg_norm_k          | 1.8      |\n",
      "| avg_norm_k_dot_g    | 13.7     |\n",
      "| entropy             | 19.4     |\n",
      "| explained_variance  | -0.85    |\n",
      "| fps                 | 451      |\n",
      "| loss                | 6.89     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.91    |\n",
      "| loss_policy         | -1.91    |\n",
      "| loss_q              | 18       |\n",
      "| mean_episode_length | 304      |\n",
      "| mean_episode_reward | 91.9     |\n",
      "| norm_grads          | 24.6     |\n",
      "| norm_grads_policy   | 8.29     |\n",
      "| norm_grads_q        | 23.2     |\n",
      "| total_timesteps     | 60020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 5.49     |\n",
      "| avg_norm_g          | 22.7     |\n",
      "| avg_norm_grads_f    | 18.9     |\n",
      "| avg_norm_k          | 2.12     |\n",
      "| avg_norm_k_dot_g    | 26.6     |\n",
      "| entropy             | 13.9     |\n",
      "| explained_variance  | 0.677    |\n",
      "| fps                 | 450      |\n",
      "| loss                | 17.2     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -5.85    |\n",
      "| loss_policy         | -5.85    |\n",
      "| loss_q              | 46.4     |\n",
      "| mean_episode_length | 283      |\n",
      "| mean_episode_reward | 106      |\n",
      "| norm_grads          | 99.4     |\n",
      "| norm_grads_policy   | 14.2     |\n",
      "| norm_grads_q        | 98.3     |\n",
      "| total_timesteps     | 62020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.147    |\n",
      "| avg_norm_g          | 4.94     |\n",
      "| avg_norm_grads_f    | 4.85     |\n",
      "| avg_norm_k          | 1.99     |\n",
      "| avg_norm_k_dot_g    | 5        |\n",
      "| entropy             | 12       |\n",
      "| explained_variance  | 0.924    |\n",
      "| fps                 | 449      |\n",
      "| loss                | 4.09     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 1.17     |\n",
      "| loss_policy         | 1.17     |\n",
      "| loss_q              | 6.08     |\n",
      "| mean_episode_length | 278      |\n",
      "| mean_episode_reward | 117      |\n",
      "| norm_grads          | 32.7     |\n",
      "| norm_grads_policy   | 5.42     |\n",
      "| norm_grads_q        | 32.2     |\n",
      "| total_timesteps     | 64020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 12.3     |\n",
      "| avg_norm_g          | 56.9     |\n",
      "| avg_norm_grads_f    | 50.4     |\n",
      "| avg_norm_k          | 2.08     |\n",
      "| avg_norm_k_dot_g    | 55.6     |\n",
      "| entropy             | 17.3     |\n",
      "| explained_variance  | -0.948   |\n",
      "| fps                 | 448      |\n",
      "| loss                | 31.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -10.2    |\n",
      "| loss_policy         | -10.2    |\n",
      "| loss_q              | 84.1     |\n",
      "| mean_episode_length | 288      |\n",
      "| mean_episode_reward | 132      |\n",
      "| norm_grads          | 188      |\n",
      "| norm_grads_policy   | 62.9     |\n",
      "| norm_grads_q        | 177      |\n",
      "| total_timesteps     | 66020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 2.62     |\n",
      "| avg_norm_g          | 11.4     |\n",
      "| avg_norm_grads_f    | 9.66     |\n",
      "| avg_norm_k          | 2.15     |\n",
      "| avg_norm_k_dot_g    | 11.7     |\n",
      "| entropy             | 11.5     |\n",
      "| explained_variance  | 0.955    |\n",
      "| fps                 | 447      |\n",
      "| loss                | 16       |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -2.41    |\n",
      "| loss_policy         | -2.41    |\n",
      "| loss_q              | 36.9     |\n",
      "| mean_episode_length | 284      |\n",
      "| mean_episode_reward | 135      |\n",
      "| norm_grads          | 158      |\n",
      "| norm_grads_policy   | 10.4     |\n",
      "| norm_grads_q        | 157      |\n",
      "| total_timesteps     | 68020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 27.1     |\n",
      "| avg_norm_grads_f    | 27.1     |\n",
      "| avg_norm_k          | 1.87     |\n",
      "| avg_norm_k_dot_g    | 24.3     |\n",
      "| entropy             | 13.7     |\n",
      "| explained_variance  | 0.281    |\n",
      "| fps                 | 446      |\n",
      "| loss                | 23.5     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 6.47     |\n",
      "| loss_policy         | 6.47     |\n",
      "| loss_q              | 34.3     |\n",
      "| mean_episode_length | 282      |\n",
      "| mean_episode_reward | 134      |\n",
      "| norm_grads          | 104      |\n",
      "| norm_grads_policy   | 10.6     |\n",
      "| norm_grads_q        | 104      |\n",
      "| total_timesteps     | 70020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 28.8     |\n",
      "| avg_norm_grads_f    | 28.8     |\n",
      "| avg_norm_k          | 2        |\n",
      "| avg_norm_k_dot_g    | 28.7     |\n",
      "| entropy             | 19.8     |\n",
      "| explained_variance  | -0.136   |\n",
      "| fps                 | 446      |\n",
      "| loss                | 46.8     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 9.51     |\n",
      "| loss_policy         | 9.51     |\n",
      "| loss_q              | 75       |\n",
      "| mean_episode_length | 283      |\n",
      "| mean_episode_reward | 138      |\n",
      "| norm_grads          | 196      |\n",
      "| norm_grads_policy   | 14.3     |\n",
      "| norm_grads_q        | 196      |\n",
      "| total_timesteps     | 72020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 9.68     |\n",
      "| avg_norm_grads_f    | 9.68     |\n",
      "| avg_norm_k          | 1.75     |\n",
      "| avg_norm_k_dot_g    | 9.65     |\n",
      "| entropy             | 3.98     |\n",
      "| explained_variance  | -1.22    |\n",
      "| fps                 | 447      |\n",
      "| loss                | 45.3     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.248    |\n",
      "| loss_policy         | 0.248    |\n",
      "| loss_q              | 90.2     |\n",
      "| mean_episode_length | 301      |\n",
      "| mean_episode_reward | 159      |\n",
      "| norm_grads          | 111      |\n",
      "| norm_grads_policy   | 3.12     |\n",
      "| norm_grads_q        | 111      |\n",
      "| total_timesteps     | 74020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 32.8     |\n",
      "| avg_norm_grads_f    | 32.8     |\n",
      "| avg_norm_k          | 1.97     |\n",
      "| avg_norm_k_dot_g    | 30.8     |\n",
      "| entropy             | 19.1     |\n",
      "| explained_variance  | 0.0673   |\n",
      "| fps                 | 449      |\n",
      "| loss                | 41.2     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 7.73     |\n",
      "| loss_policy         | 7.73     |\n",
      "| loss_q              | 67.3     |\n",
      "| mean_episode_length | 311      |\n",
      "| mean_episode_reward | 160      |\n",
      "| norm_grads          | 169      |\n",
      "| norm_grads_policy   | 26.9     |\n",
      "| norm_grads_q        | 166      |\n",
      "| total_timesteps     | 76020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 2.26     |\n",
      "| avg_norm_grads_f    | 2.26     |\n",
      "| avg_norm_k          | 1.82     |\n",
      "| avg_norm_k_dot_g    | 2.26     |\n",
      "| entropy             | 0.0964   |\n",
      "| explained_variance  | -0.724   |\n",
      "| fps                 | 450      |\n",
      "| loss                | 1.83     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.000907 |\n",
      "| loss_policy         | 0.000907 |\n",
      "| loss_q              | 3.67     |\n",
      "| mean_episode_length | 311      |\n",
      "| mean_episode_reward | 162      |\n",
      "| norm_grads          | 14.9     |\n",
      "| norm_grads_policy   | 0.0152   |\n",
      "| norm_grads_q        | 14.9     |\n",
      "| total_timesteps     | 78020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 3.75     |\n",
      "| avg_norm_g          | 14.9     |\n",
      "| avg_norm_grads_f    | 12.9     |\n",
      "| avg_norm_k          | 1.87     |\n",
      "| avg_norm_k_dot_g    | 14.2     |\n",
      "| entropy             | 15.6     |\n",
      "| explained_variance  | -1.06    |\n",
      "| fps                 | 452      |\n",
      "| loss                | 5.13     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -3.31    |\n",
      "| loss_policy         | -3.31    |\n",
      "| loss_q              | 17.2     |\n",
      "| mean_episode_length | 306      |\n",
      "| mean_episode_reward | 160      |\n",
      "| norm_grads          | 86       |\n",
      "| norm_grads_policy   | 11.4     |\n",
      "| norm_grads_q        | 85.2     |\n",
      "| total_timesteps     | 80020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.795    |\n",
      "| avg_norm_g          | 3.37     |\n",
      "| avg_norm_grads_f    | 2.84     |\n",
      "| avg_norm_k          | 1.75     |\n",
      "| avg_norm_k_dot_g    | 3.37     |\n",
      "| entropy             | 1.77     |\n",
      "| explained_variance  | 0.00216  |\n",
      "| fps                 | 453      |\n",
      "| loss                | 3.69     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.0546  |\n",
      "| loss_policy         | -0.0546  |\n",
      "| loss_q              | 7.52     |\n",
      "| mean_episode_length | 300      |\n",
      "| mean_episode_reward | 161      |\n",
      "| norm_grads          | 28.2     |\n",
      "| norm_grads_policy   | 0.947    |\n",
      "| norm_grads_q        | 28.2     |\n",
      "| total_timesteps     | 82020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 2.06     |\n",
      "| avg_norm_g          | 9.27     |\n",
      "| avg_norm_grads_f    | 8.03     |\n",
      "| avg_norm_k          | 2.04     |\n",
      "| avg_norm_k_dot_g    | 9.52     |\n",
      "| entropy             | 17.4     |\n",
      "| explained_variance  | 0.763    |\n",
      "| fps                 | 455      |\n",
      "| loss                | 0.709    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -2.46    |\n",
      "| loss_policy         | -2.46    |\n",
      "| loss_q              | 6.69     |\n",
      "| mean_episode_length | 320      |\n",
      "| mean_episode_reward | 174      |\n",
      "| norm_grads          | 58.6     |\n",
      "| norm_grads_policy   | 6.98     |\n",
      "| norm_grads_q        | 58.2     |\n",
      "| total_timesteps     | 84020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.23     |\n",
      "| avg_norm_g          | 5.61     |\n",
      "| avg_norm_grads_f    | 4.89     |\n",
      "| avg_norm_k          | 1.94     |\n",
      "| avg_norm_k_dot_g    | 5.32     |\n",
      "| entropy             | 20.7     |\n",
      "| explained_variance  | 0.615    |\n",
      "| fps                 | 457      |\n",
      "| loss                | 0.176    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.72    |\n",
      "| loss_policy         | -1.72    |\n",
      "| loss_q              | 4.21     |\n",
      "| mean_episode_length | 312      |\n",
      "| mean_episode_reward | 136      |\n",
      "| norm_grads          | 47.1     |\n",
      "| norm_grads_policy   | 7.29     |\n",
      "| norm_grads_q        | 46.6     |\n",
      "| total_timesteps     | 86020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 4.41     |\n",
      "| avg_norm_g          | 17.6     |\n",
      "| avg_norm_grads_f    | 15.2     |\n",
      "| avg_norm_k          | 1.94     |\n",
      "| avg_norm_k_dot_g    | 17.2     |\n",
      "| entropy             | 16.5     |\n",
      "| explained_variance  | -0.152   |\n",
      "| fps                 | 459      |\n",
      "| loss                | 11.9     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -5.26    |\n",
      "| loss_policy         | -5.26    |\n",
      "| loss_q              | 34.7     |\n",
      "| mean_episode_length | 284      |\n",
      "| mean_episode_reward | 109      |\n",
      "| norm_grads          | 139      |\n",
      "| norm_grads_policy   | 4.36     |\n",
      "| norm_grads_q        | 139      |\n",
      "| total_timesteps     | 88020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 43.2     |\n",
      "| avg_norm_grads_f    | 43.2     |\n",
      "| avg_norm_k          | 1.95     |\n",
      "| avg_norm_k_dot_g    | 42.9     |\n",
      "| entropy             | 16.8     |\n",
      "| explained_variance  | 0.449    |\n",
      "| fps                 | 461      |\n",
      "| loss                | 35.2     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 7.62     |\n",
      "| loss_policy         | 7.62     |\n",
      "| loss_q              | 55.5     |\n",
      "| mean_episode_length | 259      |\n",
      "| mean_episode_reward | 87.2     |\n",
      "| norm_grads          | 156      |\n",
      "| norm_grads_policy   | 13.2     |\n",
      "| norm_grads_q        | 155      |\n",
      "| total_timesteps     | 90020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0917   |\n",
      "| avg_norm_g          | 7.89     |\n",
      "| avg_norm_grads_f    | 7.83     |\n",
      "| avg_norm_k          | 2.14     |\n",
      "| avg_norm_k_dot_g    | 8.34     |\n",
      "| entropy             | 15.4     |\n",
      "| explained_variance  | 0.363    |\n",
      "| fps                 | 463      |\n",
      "| loss                | 4.49     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 1.91     |\n",
      "| loss_policy         | 1.91     |\n",
      "| loss_q              | 5.47     |\n",
      "| mean_episode_length | 223      |\n",
      "| mean_episode_reward | 56.3     |\n",
      "| norm_grads          | 37.9     |\n",
      "| norm_grads_policy   | 13.7     |\n",
      "| norm_grads_q        | 35.3     |\n",
      "| total_timesteps     | 92020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 11.1     |\n",
      "| avg_norm_g          | 45.6     |\n",
      "| avg_norm_grads_f    | 39.1     |\n",
      "| avg_norm_k          | 2.07     |\n",
      "| avg_norm_k_dot_g    | 48.7     |\n",
      "| entropy             | 17       |\n",
      "| explained_variance  | 0.229    |\n",
      "| fps                 | 465      |\n",
      "| loss                | 0.427    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -3.73    |\n",
      "| loss_policy         | -3.73    |\n",
      "| loss_q              | 8.64     |\n",
      "| mean_episode_length | 214      |\n",
      "| mean_episode_reward | 46.5     |\n",
      "| norm_grads          | 66.1     |\n",
      "| norm_grads_policy   | 10       |\n",
      "| norm_grads_q        | 65.4     |\n",
      "| total_timesteps     | 94020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 0.104    |\n",
      "| avg_norm_g          | 11.1     |\n",
      "| avg_norm_grads_f    | 11       |\n",
      "| avg_norm_k          | 1.97     |\n",
      "| avg_norm_k_dot_g    | 11       |\n",
      "| entropy             | 12.6     |\n",
      "| explained_variance  | 0.721    |\n",
      "| fps                 | 467      |\n",
      "| loss                | 17.3     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 2.59     |\n",
      "| loss_policy         | 2.59     |\n",
      "| loss_q              | 29.6     |\n",
      "| mean_episode_length | 209      |\n",
      "| mean_episode_reward | 38.9     |\n",
      "| norm_grads          | 176      |\n",
      "| norm_grads_policy   | 8.68     |\n",
      "| norm_grads_q        | 176      |\n",
      "| total_timesteps     | 96020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0829   |\n",
      "| avg_norm_g          | 5        |\n",
      "| avg_norm_grads_f    | 4.94     |\n",
      "| avg_norm_k          | 2.03     |\n",
      "| avg_norm_k_dot_g    | 5.02     |\n",
      "| entropy             | 18.7     |\n",
      "| explained_variance  | 0.873    |\n",
      "| fps                 | 469      |\n",
      "| loss                | 2.9      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 1.38     |\n",
      "| loss_policy         | 1.38     |\n",
      "| loss_q              | 3.42     |\n",
      "| mean_episode_length | 208      |\n",
      "| mean_episode_reward | 31.1     |\n",
      "| norm_grads          | 44       |\n",
      "| norm_grads_policy   | 3.55     |\n",
      "| norm_grads_q        | 43.8     |\n",
      "| total_timesteps     | 98020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.acer.acer_simple.ACER at 0x24fb8de2c48>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps = 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-apollo",
   "metadata": {},
   "source": [
    "# 3. Save and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "prospective-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "given-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ACER_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-somerset",
   "metadata": {},
   "source": [
    "# 4. Reloading Model From Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deadly-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "revised-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ACER.load(\"ACER_model\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "possible-illness",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-69392ce50071>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \"\"\"\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\envs\\box2d\\lunar_lander.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    374\u001b[0m                                      color=(0.8, 0.8, 0))\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, return_rgb_array)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mflip\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_always_dwm\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dwm_composition_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                     \u001b[0m_dwmapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDwmFlush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "elect-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-hayes",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
